{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Tokenization of Question\n",
    "def tokenization(list_of_strings):\n",
    "    BOW_Query=list_of_strings.split()\n",
    "    return BOW_Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Removal of Stop words in the Question\n",
    "def stop_words(strings_list):\n",
    "    \n",
    "    stop = set(stopwords.words('english'))\n",
    "    bow_query_sw=([i for i in strings_list if i not in stop])\n",
    "    return bow_query_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Stemming of the Question terms\n",
    "def stemmer(strings_list):\n",
    "    \n",
    "    query_words=[]\n",
    "    ps = PorterStemmer()\n",
    "    for w in strings_list:\n",
    "        query_words.append(ps.stem(w))\n",
    "    return query_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Removal of stop words in the answers\n",
    "def sw_co(comments):    \n",
    "    stop = set(stopwords.words('english'))\n",
    "    comments_sw=[]\n",
    "    for item in comments:\n",
    "        stop_words=([i for i in item.lower().split() if i not in stop])\n",
    "        comments_sw.append(stop_words)\n",
    "    return comments_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Stemming the words in the comments\n",
    "def stemmer_co(strings):\n",
    "    comments_st=[]\n",
    "    ps = PorterStemmer()\n",
    "    for items in strings:\n",
    "        comment_st_each=[]\n",
    "        for w in items:\n",
    "            comment_st_each.append(ps.stem(w))\n",
    "        comments_st.append(comment_st_each)\n",
    "    return comments_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating the unique words list from the above list.\n",
    "#Creating a dictionary with word counter\n",
    "def word_counter(strings):    \n",
    "    my_counter = {}\n",
    "    for line in strings:\n",
    "        for word in line:\n",
    "            my_counter[word] = my_counter.get(word, 0) + 1\n",
    "    return my_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Extracting only the words (which corresponds to the dictionary keys)\n",
    "def unique_words(dictionary):    \n",
    "    comments_words=[]\n",
    "    for item in dictionary.keys():\n",
    "        comments_words.append(item)\n",
    "    return comments_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def wordset(querydoc,commentsdoc):\n",
    "    wordset=set(querydoc).union(set(commentsdoc))\n",
    "    return wordset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Initialization with Zeros\n",
    "def tf_raw_query(query_strings,wordset):    \n",
    "    worddict_query=dict.fromkeys(wordset,0)    \n",
    "    for word in query_strings:\n",
    "        worddict_query[word]+=1\n",
    "    return worddict_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Calculation of the tf-weight terms\n",
    "def tf_weight(words_raw):    \n",
    "    dict_tf_wt={}\n",
    "    import math\n",
    "    for key,val in words_raw.items():\n",
    "        if val!=0:\n",
    "            value=1+(math.log(val))\n",
    "        else:\n",
    "            value=0\n",
    "        dict_tf_wt[key]=value\n",
    "    return dict_tf_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dfdfdf(ww,dd):\n",
    "    dict_dfdf={}\n",
    "    for item in ww:\n",
    "        #print (item)\n",
    "        co=0\n",
    "        for items in Comments_Stemming:\n",
    "            #print (items)\n",
    "            if item in items:\n",
    "                co+=1\n",
    "            else:\n",
    "                pass\n",
    "            dict_dfdf[item]=co\n",
    "            #print ('First word')\n",
    "    return dict_dfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Calculating the idf for a query\n",
    "def idf_query1(dfw):\n",
    "    idf=[]\n",
    "    import math\n",
    "    for item in dfw['df']:\n",
    "        if item !=0:\n",
    "            value=math.log(len(Comments_Stemming)/item)\n",
    "        else:\n",
    "            value=0\n",
    "        idf.append(value)\n",
    "    dfw[\"idf\"]=idf\n",
    "    return dfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Normalizing the weights\n",
    "def norm_q(df_norm):    \n",
    "    sum1=0.0\n",
    "    for item in df_norm['wt']:\n",
    "        sq=item*item\n",
    "        sum1+=sq\n",
    "    import math\n",
    "    norm_q=[]\n",
    "    for itemm in df_norm['wt']:\n",
    "        if itemm==0:\n",
    "            deno=0\n",
    "        else:\n",
    "            deno=itemm/(math.sqrt((sum1)))\n",
    "        norm_q.append(deno)\n",
    "    df_norm[\"nor_q\"]=norm_q\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def log_wt(val1):\n",
    "    import math\n",
    "    if val1!=0:\n",
    "        value=1+(math.log(val1))\n",
    "    else:\n",
    "        value=0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Importing the Question-Comments XML file,Identifying the Question-Comments within the XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Importing the XML file and required libraries\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "tree = ET.parse('SemEval2016-Task3-CQA-QL-train-part1-subtaskA.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing the Question ID  Q1_R1\n",
      "Accessing the comments for  Q1_R1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Miniconda3\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:103: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing the Question ID  Q1_R6\n",
      "Accessing the comments for  Q1_R6\n",
      "Accessing the Question ID  Q1_R8\n",
      "Accessing the comments for  Q1_R8\n",
      "Accessing the Question ID  Q1_R10\n",
      "Accessing the comments for  Q1_R10\n"
     ]
    }
   ],
   "source": [
    "scores={}\n",
    "for thread in root.findall(\"Thread\"):\n",
    "    dict_score={}\n",
    "    for question in thread.findall('RelQuestion'):\n",
    "        Question_ID=question.attrib['RELQ_ID']\n",
    "        Question_text=question.find('RelQBody').text\n",
    "        if not Question_text:\n",
    "            continue\n",
    "        print (\"Accessing the Question ID \",Question_ID)\n",
    "        #Tokenization of the Question        \n",
    "        Tokenized_Question=tokenization(Question_text)\n",
    "        \n",
    "        #Removing the stop words from the Question        \n",
    "        Question_Stop_words=stop_words(Tokenized_Question)        \n",
    "        \n",
    "        #Stemming the words in Question        \n",
    "        Stemmed_question=stemmer(Question_Stop_words)\n",
    "    \n",
    "    if not Question_text:\n",
    "            print ('skipping',Question_ID)\n",
    "            continue\n",
    "            \n",
    "    print (\"Accessing the comments for \",Question_ID)  \n",
    "    \n",
    "    #Comments\n",
    "    comments=[]\n",
    "    \n",
    "    ids=[]\n",
    "    for each_answer in thread.findall('RelComment'):\n",
    "        Answer_ID=each_answer.attrib['RELC_ID']\n",
    "        Answer_text=each_answer.find('RelCText').text\n",
    "        comments.append(Answer_text)\n",
    "        ids.append(Answer_ID)\n",
    "    \n",
    "       \n",
    "    #Removing stop words from the Comments    \n",
    "    Comments_stop_words=sw_co(comments)\n",
    "    \n",
    "    #Stemming the words in the comments\n",
    "    \n",
    "    Comments_Stemming=stemmer_co(Comments_stop_words) \n",
    "    \n",
    "    \n",
    "    #Creating a wordset for the comments\n",
    "    counter1=word_counter(Comments_Stemming)\n",
    "    unique_words1=unique_words(counter1)\n",
    "    wordset1=wordset(Stemmed_question,unique_words1)\n",
    "    \n",
    "    \n",
    "    #Calculating the raw terms in the comments\n",
    "    tf_raw=tf_raw_query(Stemmed_question,wordset1) \n",
    "    tf_wt=tf_weight(tf_raw)\n",
    "    \n",
    "    dl=list(wordset1)   \n",
    "    df_query=dfdfdf(dl,Comments_Stemming)\n",
    "\n",
    "    #Appending the tf-raw, tf-wt, df into a dataframe\n",
    "    \n",
    "    dframe=pd.DataFrame.from_dict([tf_raw,tf_wt,df_query],orient='columns')\n",
    "    df=dframe.transpose()\n",
    "    summary_of_results=df.rename(columns={0: 'tf_raw',1: 'tf_weight',2: 'df'})\n",
    "    \n",
    "    #Calculating the IDF for the query\n",
    "    \n",
    "    idf_query=idf_query1(summary_of_results)    \n",
    "    idf_query[\"wt\"]=idf_query.idf*idf_query.tf_weight\n",
    "    #Normalization\n",
    "    \n",
    "    norm_query=norm_q(idf_query)\n",
    "    \n",
    "    #Calculating the raw-terms for all the comments\n",
    "    \n",
    "    result=pd.DataFrame()\n",
    "    for item in Comments_Stemming:\n",
    "        worddict_terms=dict.fromkeys(wordset1,0)  \n",
    "        frames=pd.DataFrame()\n",
    "        for items in item:\n",
    "            worddict_terms[items]+=1\n",
    "            df_com_c1=pd.DataFrame.from_dict([worddict_terms])\n",
    "        frames=[result,df_com_c1]\n",
    "        result = pd.concat(frames)\n",
    "    Comments_raw_terms=result.transpose()\n",
    "    Comments_weights=Comments_raw_terms.applymap(log_wt)\n",
    "    \n",
    "    #Adding the column name to the Dataframe\n",
    "    Comments_weights.columns=[\"tf_doc_wt_1\",\"tf_doc_wt_2\",\"tf_doc_wt_3\",\"tf_doc_wt_4\",\"tf_doc_wt_5\",\n",
    "                              \"tf_doc_wt_6\",\"tf_doc_wt_7\",\"tf_doc_wt_8\",\"tf_doc_wt_9\",\"tf_doc_wt_10\"]\n",
    "\n",
    "    #Normalization of all the comments weights\n",
    "    \n",
    "    counter=1\n",
    "    for item in Comments_weights:\n",
    "        sum2=0.0\n",
    "        for items in Comments_weights[item]:\n",
    "            sq1=items*items\n",
    "            sum2+=sq1\n",
    "            import math\n",
    "            norm_q_d=[]\n",
    "            for itemw in Comments_weights[item]:\n",
    "                if itemw==0:\n",
    "                    deno=0\n",
    "                else:\n",
    "                    deno=itemw/math.sqrt((sum2))\n",
    "                norm_q_d.append(deno)\n",
    "        s=str(counter)\n",
    "        Comments_weights[s]=norm_q_d\n",
    "        counter+=1\n",
    "    #Comments_weights\n",
    "    #Keeping the column weights \n",
    "    cols = [0,1,2,3,4,5,6,7,8,9]\n",
    "    Comments_weights.drop(Comments_weights.columns[cols],axis=1,inplace=True)\n",
    "    \n",
    "    #product\n",
    "    columns = Comments_weights.columns[:]\n",
    "    for item in columns:\n",
    "        Comments_weights[item] *= norm_query['nor_q']\n",
    "        \n",
    "    #Replacing the NaN values with Zero's\n",
    "    Comments_weights_corrected=Comments_weights.fillna('0')\n",
    "\n",
    "    #Query - Documents score\n",
    "    \n",
    "    Cosine_Score=Comments_weights_corrected.sum(axis=0)\n",
    "    scoreee=list(Cosine_Score)\n",
    "    dictionary = dict(zip(ids, scoreee))\n",
    "    scores.update(dictionary)\n",
    "    #print ('printing cosine score')\n",
    "    #print(dictionary)\n",
    "    \n",
    "    for item in dictionary.keys():\n",
    "        output=str([Question_ID,item,dictionary[item]])\n",
    "        target = open('task.relevancy', 'a')\n",
    "        target.write(output+'\\n')\n",
    "#print (scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
